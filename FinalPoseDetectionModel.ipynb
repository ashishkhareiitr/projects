{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FinalPoseDetectionModel.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashishkhareiitr/projects/blob/master/FinalPoseDetectionModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "FWL9nmh1u1bj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Capstone Project - Yoga Pose Detection \n",
        "\n",
        "     by Ashish Khare , Amalendu Tiwari , Harshada Khanvilkar and Divya Tripathi**"
      ]
    },
    {
      "metadata": {
        "id": "av03T_y6usNx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## ***# Table of Contents***"
      ]
    },
    {
      "metadata": {
        "id": "u4J6sxgnuncg",
        "colab_type": "toc"
      },
      "cell_type": "markdown",
      "source": [
        ">[Capstone Project - Yoga Pose Detection by Ashish Khare , Amalendu Tiwari , Harshada Khanvilkar and Divya Tripathi](#updateTitle=true&folderId=1Iapkl62Ujq_fuCjoQQqCFUtdpPIw19Ng&scrollTo=FWL9nmh1u1bj)\n",
        "\n",
        ">>[# Table of Contents](#updateTitle=true&folderId=1Iapkl62Ujq_fuCjoQQqCFUtdpPIw19Ng&scrollTo=av03T_y6usNx)\n",
        "\n",
        ">[Load Yolo Configuration](#updateTitle=true&folderId=1Iapkl62Ujq_fuCjoQQqCFUtdpPIw19Ng&scrollTo=w_-ezk6Bqu03)\n",
        "\n",
        ">[Load Pacakges](#updateTitle=true&folderId=1Iapkl62Ujq_fuCjoQQqCFUtdpPIw19Ng&scrollTo=KLW5csvls_zm)\n",
        "\n",
        ">[Function : Get Output Layers](#updateTitle=true&folderId=1Iapkl62Ujq_fuCjoQQqCFUtdpPIw19Ng&scrollTo=uCvleoqytQtd)\n",
        "\n",
        ">[Function : Draw Prediction](#updateTitle=true&folderId=1Iapkl62Ujq_fuCjoQQqCFUtdpPIw19Ng&scrollTo=yUR830lzvOUe)\n",
        "\n",
        ">[Function : Load Images](#updateTitle=true&folderId=1Iapkl62Ujq_fuCjoQQqCFUtdpPIw19Ng&scrollTo=OsXqj1-3ydoa)\n",
        "\n",
        ">[Function : Canny Edge](#updateTitle=true&folderId=1Iapkl62Ujq_fuCjoQQqCFUtdpPIw19Ng&scrollTo=VMDjAXtfvhYV)\n",
        "\n",
        ">[Function : Calculate key frame thresold](#updateTitle=true&folderId=1Iapkl62Ujq_fuCjoQQqCFUtdpPIw19Ng&scrollTo=hq0HaAITjnmy)\n",
        "\n",
        ">[Function : Split Frames](#updateTitle=true&folderId=1Iapkl62Ujq_fuCjoQQqCFUtdpPIw19Ng&scrollTo=HlJXFUSZjs5L)\n",
        "\n",
        ">[Function : Train Data Prep](#updateTitle=true&folderId=1Iapkl62Ujq_fuCjoQQqCFUtdpPIw19Ng&scrollTo=XBnFSTduy1p2)\n",
        "\n",
        ">[Function : Test Data Prep](#updateTitle=true&folderId=1Iapkl62Ujq_fuCjoQQqCFUtdpPIw19Ng&scrollTo=qUY5FpWoy9LS)\n",
        "\n",
        ">[Function : Yolo object detection and crop human](#updateTitle=true&folderId=1Iapkl62Ujq_fuCjoQQqCFUtdpPIw19Ng&scrollTo=Z6v0EV1NkBUe)\n",
        "\n",
        ">>[Please make sure yolov3.cfg , yolov3.txt and yolov3.weights are uploaded](#updateTitle=true&folderId=1Iapkl62Ujq_fuCjoQQqCFUtdpPIw19Ng&scrollTo=Z6v0EV1NkBUe)\n",
        "\n",
        ">[CNN training and Accuracy](#updateTitle=true&folderId=1Iapkl62Ujq_fuCjoQQqCFUtdpPIw19Ng&scrollTo=pmpXUP_TzIwT)\n",
        "\n",
        ">[Running test/train data labels and CNN](#updateTitle=true&folderId=1Iapkl62Ujq_fuCjoQQqCFUtdpPIw19Ng&scrollTo=szNGmlrLzV7f)\n",
        "\n",
        ">[Predict using saved model](#updateTitle=true&folderId=1Iapkl62Ujq_fuCjoQQqCFUtdpPIw19Ng&scrollTo=t-Lo_rRUzvB9)\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "w_-ezk6Bqu03",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load Yolo Configuration"
      ]
    },
    {
      "metadata": {
        "id": "q2doqnIDp_aW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget https://pjreddie.com/media/files/yolov3.weights\n",
        "\n",
        "# please also upload yolov3.txt and yolov3.cfg  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KLW5csvls_zm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load Pacakges"
      ]
    },
    {
      "metadata": {
        "id": "00xyzlAmtDU-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "99aa931b-c2ac-4945-cdcc-e3b50a6cd6af"
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import cv2\n",
        "import argparse\n",
        "import sys\n",
        "import PIL.Image\n",
        "import os\n",
        "from sys import platform\n",
        "import re\n",
        "from os import listdir\n",
        "import ntpath #for retrieving filename\n",
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.utils import np_utils\n",
        "from keras import backend as K\n",
        "from sklearn.cluster import KMeans  \n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "import pylab as pl\n",
        "import matplotlib.pyplot as plt\n",
        "from statistics import stdev \n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing import image"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "uCvleoqytQtd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Function : Get Output Layers\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "FIBdYzeFuiBn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_output_layers(net):\n",
        "    \n",
        "    layer_names = net.getLayerNames()\n",
        "    \n",
        "    output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
        "\n",
        "    return output_layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yUR830lzvOUe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Function : Draw Prediction"
      ]
    },
    {
      "metadata": {
        "id": "RNQZR6NEvY9p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def draw_prediction(img, class_id, confidence, x, y, x_plus_w, y_plus_h):\n",
        "\n",
        "    label = str(classes[class_id])\n",
        "\n",
        "    color = COLORS[class_id]\n",
        "\n",
        "    image = cv2.rectangle(img, (x,y), (x_plus_w,y_plus_h), color, 2)\n",
        "\n",
        "    cv2.putText(img, label, (x-10,y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "    \n",
        "    return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OsXqj1-3ydoa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Function : Load Images"
      ]
    },
    {
      "metadata": {
        "id": "DNOwfjuaygh4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "_nsre = re.compile('([0-9]+)')\n",
        "\n",
        "def natural_sort_key(s):\n",
        "    return [int(text) if text.isdigit() else text.lower()\n",
        "            for text in re.split(_nsre, s)]  \n",
        "  \n",
        "def loadImages(path):\n",
        "    # return array of images\n",
        "    \n",
        "    imagesList = listdir(path)\n",
        "    imagesList.sort(key=natural_sort_key)\n",
        "    #imagesList = imagesList.sort()     \n",
        "    loadedImages = []\n",
        "    for image in imagesList:\n",
        "      if image is not None:\n",
        "        img = PIL.Image.open(path + image)\n",
        "        loadedImages.append(img)\n",
        "      else:\n",
        "        print('not loaded')\n",
        "    \n",
        "       \n",
        "    return loadedImages"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VMDjAXtfvhYV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Function : Canny Edge"
      ]
    },
    {
      "metadata": {
        "id": "N4BJHZUd1isc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "############canny edge detection############\n",
        " \n",
        "def auto_canny(image, sigma=0.33):\n",
        "\t# compute the median of the single channel pixel intensities\n",
        "\tv = np.median(image)\n",
        " \n",
        "\t# apply automatic Canny edge detection using the computed median\n",
        "\tlower = int(max(0, (1.0 - sigma) * v))\n",
        "\tupper = int(min(255, (1.0 + sigma) * v))\n",
        "\tedged = cv2.Canny(image, lower, upper)\n",
        " \n",
        "\t# return the edged image\n",
        "\treturn edged"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hq0HaAITjnmy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Function : Calculate key frame thresold"
      ]
    },
    {
      "metadata": {
        "id": "80Qv0nWr13Cl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##############Key Frames thresold ##########################\n",
        "def KeyFrameThreshold(VideoPath):\n",
        "\n",
        "    print('calculating key frame thresold.....')\n",
        "    fgbg = cv2.createBackgroundSubtractorMOG2(history=20, varThreshold=25, detectShadows=True)\n",
        "    cap = cv2.VideoCapture(VideoPath)\n",
        "    # Read the first frame.\n",
        "    ret, prev_frame = cap.read()\n",
        "    prev_edges = auto_canny(prev_frame)\n",
        "    storediff =[]\n",
        "    \n",
        "   \n",
        "    while ret:\n",
        "        ret, curr_frame = cap.read()\n",
        "        \n",
        "        if ret:\n",
        "               \n",
        "            gray = cv2.cvtColor(curr_frame, cv2.COLOR_BGR2GRAY)\n",
        "            blurred = cv2.GaussianBlur(gray, (3, 3), 0)\n",
        "            \n",
        "            curr_frame_bg = fgbg.apply(blurred)\n",
        "            #curr_edges = cv2.Canny(curr_frame_bg,100,200)\n",
        "            curr_edges = auto_canny(curr_frame_bg)\n",
        "            \n",
        "            diff = cv2.absdiff(curr_edges, prev_edges)\n",
        "            non_zero_count = np.count_nonzero(diff)\n",
        "            storediff.append(non_zero_count)\n",
        "            #icount = icount +1\n",
        "            #print(non_zero_count)\n",
        "            prev_edges = curr_edges\n",
        "                           \n",
        "            #print(diff)\n",
        "            #meandiff = meandiff + diff\n",
        "            #print(meandiff)\n",
        "            #cv2.imshow('Original',frame) \n",
        "      \n",
        "            # finds edges in the input image image and \n",
        "            # marks them in the output map edges \n",
        "            #edges = cv2.Canny(frame,100,200) \n",
        "      \n",
        "            # Display edges in a frame \n",
        "            #cv2.imshow('Edges',edges) \n",
        "            #storediff.append(diff)\n",
        "    meanstorediff =  np.mean(storediff)\n",
        "    stdstorediff =   np.std(storediff)\n",
        "    min_p_frame_thresh = meanstorediff-1.5*stdstorediff\n",
        "    max_p_frame_thresh = meanstorediff+1.5*stdstorediff \n",
        "    \n",
        "    print('completed calculating key frame thresold.')\n",
        "    \n",
        "    return min_p_frame_thresh,max_p_frame_thresh\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HlJXFUSZjs5L",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Function : Split Frames\n",
        "\n",
        "> Read videos from folder and store as keyframes\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "jJe1OJt3jvYC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#########################Extracting and saving key frames################################\n",
        "            \n",
        "def KeyFrame(VideoPath,KeyFrameFolder,minThreshold,maxThreshold):\n",
        "\n",
        "    print('extracting key frames.....')\n",
        "    cap = cv2.VideoCapture(VideoPath)\n",
        "    # Read the first frame.\n",
        "    ret, prev_frame = cap.read()\n",
        "    #prev_frame = cv2.resize(prev_frame, (128, 128))    \n",
        "    prev_edges = auto_canny(prev_frame)\n",
        "    \n",
        "    #prev_edges = cv2.Canny(prev_frame,100,200)\n",
        "    count = 0\n",
        "    vfolder = KeyFrameFolder\n",
        "    os.mkdir(vfolder)\n",
        "    \n",
        "    fgbg = cv2.createBackgroundSubtractorMOG2(history=20, varThreshold=25, detectShadows=True)\n",
        "    #scaling_factor = 1.5\n",
        "    while ret:\n",
        "      ret, curr_frame = cap.read()\n",
        "      #curr_frame = cv2.resize(curr_frame, (128, 128)) \n",
        "      #curr_frame = cv2.resize(curr_frame, None, fx=scaling_factor, fy=scaling_factor,interpolation=cv2.INTER_AREA)\n",
        "      if ret:\n",
        "        gray = cv2.cvtColor(curr_frame, cv2.COLOR_BGR2GRAY)\n",
        "        blurred = cv2.GaussianBlur(gray, (3, 3), 0)\n",
        "        curr_frame_bg = fgbg.apply(blurred)\n",
        "        curr_edges = auto_canny(curr_frame_bg)\n",
        "           \n",
        "        diff = cv2.absdiff(curr_edges, prev_edges)\n",
        "        non_zero_count = np.count_nonzero(diff)\n",
        "        #print(non_zero_count)\n",
        "          \n",
        "        if non_zero_count > maxThreshold:\n",
        "          print('Writing Key-Frame...')\n",
        "          count = count+1\n",
        "          cv2.imwrite(os.path.join(vfolder,\"frame{:d}.jpg\".format(count)), curr_frame) \n",
        "          #cv2.imshow('Original',curr_frame) \n",
        "          prev_edges = curr_edges\n",
        "    print('completed extracting key frames.')    \n",
        "    return count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XBnFSTduy1p2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Function : Train Data Prep"
      ]
    },
    {
      "metadata": {
        "id": "j3zsB_6Sy4aj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "######################################### train data prep work #####################\n",
        "\n",
        "def TrainDataPrep(TrainDataPath,img_row,img_col):\n",
        "\n",
        "    train_data = []\n",
        "    train_labels_one_hot =[]\n",
        "    trainfileList =[]\n",
        "    \n",
        "    for root, dirs, files in os.walk(TrainDataPath):\n",
        "        for file in files:\n",
        "            if file.endswith(\".jpg\"):\n",
        "                 fullName = os.path.join(root, file)\n",
        "                 trainfileList.append(fullName)\n",
        "    \n",
        "    fgbg = cv2.createBackgroundSubtractorMOG2(history=20, varThreshold=25, detectShadows=True) \n",
        "    for imagePath in trainfileList:\n",
        "        \n",
        "        image = cv2.imread(imagePath)\n",
        "        if image is not None:\n",
        "            \n",
        "            image = cv2.resize(image, (img_row,img_col))\n",
        "            #image = cv2.resize(image, (128, 128))\n",
        "            \n",
        "            #gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "            #blurred = cv2.GaussianBlur(gray, (3, 3), 0)\n",
        "            #curr_frame_bg = fgbg.apply(blurred)\n",
        "            #image = auto_canny(curr_frame_bg)\n",
        "            \n",
        "            image = img_to_array(image)\n",
        "            #x = x.reshape((1,) + x.shape)\n",
        "            train_data.append(image)\n",
        "            train_data[0].shape\n",
        "            path = os.path.split(imagePath)\n",
        "            x = path[0]\n",
        "            #x = re.sub(r\"\\\\\",r\"\\\\\\\\\", x)\n",
        "            #print(x)\n",
        "            label = x.split(\"/\")[2]\n",
        "            label = int(label)\n",
        "            train_labels_one_hot.append(label)\n",
        "            print(imagePath)\n",
        "            print(label)\n",
        "            \n",
        "        else:\n",
        "                print(imagePath,\"image  not loaded\")\n",
        "        \n",
        "    train_data = np.array(train_data)\n",
        "    train_labels_one_hot = np.array(train_labels_one_hot)\n",
        "    print('train shape:', train_data.shape)\n",
        "    print(train_data.shape[0], 'train samples')\n",
        "    \n",
        "    return train_data,train_labels_one_hot\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qUY5FpWoy9LS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Function : Test Data Prep"
      ]
    },
    {
      "metadata": {
        "id": "g_GHiyd5zASh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#################################test data prep work ###############################################3\n",
        "\n",
        "def TestDataPrep(TestDataPath,img_row,img_col):\n",
        "\n",
        "    test_data = []\n",
        "    test_labels_one_hot =[]\n",
        "    testfileList =[]\n",
        "    \n",
        "    for root, dirs, files in os.walk(TestDataPath):\n",
        "        for file in files:\n",
        "            if file.endswith(\".jpg\"):\n",
        "                 fullName = os.path.join(root, file)\n",
        "                 testfileList.append(fullName)\n",
        "    \n",
        "    fgbg = cv2.createBackgroundSubtractorMOG2(history=20, varThreshold=25, detectShadows=True)\n",
        "    for imagePath in testfileList:\n",
        "        \n",
        "        image = cv2.imread(imagePath)\n",
        "        if image is not None:\n",
        "            \n",
        "            image = cv2.resize(image, (img_row,img_col))\n",
        "            #image = cv2.resize(image, (128, 128))\n",
        "                \n",
        "            #gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "            #blurred = cv2.GaussianBlur(gray, (3, 3), 0)\n",
        "            #curr_frame_bg = fgbg.apply(blurred)\n",
        "            #image = auto_canny(curr_frame_bg)\n",
        "            \n",
        "            image = img_to_array(image)\n",
        "            #x = x.reshape((1,) + x.shape)\n",
        "            test_data.append(image)\n",
        "            test_data[0].shape\n",
        "            path = os.path.split(imagePath)\n",
        "            x = path[0]\n",
        "            label = x.split(\"/\")[2]\n",
        "            label = int(label)\n",
        "            test_labels_one_hot.append(label)\n",
        "            print(imagePath)\n",
        "            print(label)\n",
        "            \n",
        "        else:\n",
        "                print(imagePath,\"image not loaded\")\n",
        "        \n",
        "    \n",
        "    test_data = np.array(test_data)\n",
        "    test_labels_one_hot = np.array(test_labels_one_hot)\n",
        "    print('test shape:', test_data.shape)\n",
        "    print(test_data.shape[0], 'test samples')  \n",
        "    \n",
        "    return test_data,test_labels_one_hot\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z6v0EV1NkBUe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Function : Yolo object detection and crop human\n",
        "\n",
        "## > # Please make sure yolov3.cfg , yolov3.txt and yolov3.weights are uploaded\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "S5le6MkDkH8f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "path_loadImages =  \"backup data/test/2/\"\n",
        "count = 0\n",
        "\n",
        "\n",
        "imgs = loadImages(path_loadImages)\n",
        "\n",
        "#fgbg = cv2.createBackgroundSubtractorMOG2(history=15, varThreshold=25, detectShadows=False) \n",
        "\n",
        "for i in range(1,len(imgs)):\n",
        "  \n",
        "  print(imgs[i-1].filename)\n",
        "\n",
        "  image=cv2.imread(imgs[i-1].filename)\n",
        "\n",
        "#image = cv2.imread(\"frame328.jpg\")\n",
        "\n",
        "  Width = image.shape[1]\n",
        "  Height = image.shape[0]\n",
        "  scale = 0.00392\n",
        "\n",
        "  classes = None\n",
        "\n",
        "  with open(\"yolov3.txt\", 'r') as f:\n",
        "    \n",
        "    classes = [line.strip() for line in f.readlines()]\n",
        "\n",
        "  COLORS = np.random.uniform(0, 255, size=(len(classes), 3))\n",
        "\n",
        "  weights = \"yolov3.weights\"\n",
        "  config = \"yolov3.cfg\"\n",
        "\n",
        "  net = cv2.dnn.readNet(weights, config)\n",
        "\n",
        "  blob = cv2.dnn.blobFromImage(image, scale, (416,416), (0,0,0), True, crop=False)\n",
        "\n",
        "  net.setInput(blob)\n",
        "\n",
        "  outs = net.forward(get_output_layers(net))\n",
        "\n",
        "  class_ids = []\n",
        "  confidences = []\n",
        "  boxes = []\n",
        "  conf_threshold = 0.5\n",
        "  nms_threshold = 0.4\n",
        "\n",
        "\n",
        "  for out in outs:\n",
        "      for detection in out:\n",
        "          scores = detection[5:]\n",
        "          class_id = np.argmax(scores)\n",
        "          confidence = scores[class_id]\n",
        "          if confidence > 0.5:\n",
        "              center_x = int(detection[0] * Width)\n",
        "              center_y = int(detection[1] * Height)\n",
        "              w = int(detection[2] * Width)\n",
        "              h = int(detection[3] * Height)\n",
        "              x = center_x - w / 2\n",
        "              y = center_y - h / 2\n",
        "              class_ids.append(class_id)\n",
        "              confidences.append(float(confidence))\n",
        "              boxes.append([x, y, w, h])\n",
        "\n",
        "\n",
        "  indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n",
        "\n",
        "  for i in indices:\n",
        "      i = i[0]\n",
        "      box = boxes[i]\n",
        "      x = box[0]\n",
        "      y = box[1]\n",
        "      w = box[2]\n",
        "      h = box[3]\n",
        "      draw_prediction(image, class_ids[i], confidences[i], round(x), round(y), round(x+w), round(y+h))\n",
        "\n",
        "  #cv2.imshow(\"object detection\", image)\n",
        "  #cv2.waitKey()\n",
        "\n",
        "  #cv2.imwrite(\"object-detection.jpg\", image)\n",
        "  #cv2.destroyAllWindows()\n",
        "  cv2.imwrite(os.path.join(os.getcwd(),\"2test_yolo{:d}.jpg\".format(count)),image )\n",
        "  \n",
        "  xx = int(x)\n",
        "  yy = int(y)\n",
        "  ww = int(w)\n",
        "  hh = int(h)\n",
        "  \n",
        "  img = cv2.imread(\"2test_yolo{:d}.jpg\".format(count))\n",
        "  print(xx,yy,ww,hh)\n",
        "  \n",
        "  if img is not None:\n",
        "    \n",
        "    \n",
        "    crop_img = img[yy:yy+hh,xx:xx+ww]\n",
        "  #crop_img = img[604:700,420:900]\n",
        "  #y:y+h, x:x+w]\n",
        "  #cv2.imshow(\"cropped\", crop_img)\n",
        "    cv2.imwrite(os.path.join(os.getcwd(),\"2test_cropyolo{:d}.jpg\".format(count)),crop_img)\n",
        "  else:\n",
        "    print(\"not cropped\")\n",
        "    \n",
        "  \n",
        "  cropped_img = cv2.imread(\"2test_cropyolo{:d}.jpg\".format(count))\n",
        "  \n",
        "  if cropped_img is not None:\n",
        "    \n",
        "    gray = cv2.cvtColor(cropped_img, cv2.COLOR_BGR2GRAY)\n",
        "  else:\n",
        "    print(\"not able to convert to gray\")\n",
        "    \n",
        "  #blurred = cv2.GaussianBlur(gray, (3, 3), 0)\n",
        "  #curr_frame_bg = fgbg.apply(cropped_img)\n",
        "  \n",
        "  cv2.imwrite(os.path.join(os.getcwd(),\"2test_CropBGyolo{:d}.jpg\".format(count)),gray)\n",
        "  \n",
        "  count = count +1\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pmpXUP_TzIwT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# CNN training and Accuracy"
      ]
    },
    {
      "metadata": {
        "id": "7ULfHgmCzMV4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "########################CNN model################################################################\n",
        "\n",
        "def YogaCNNModel(train_data,train_labels_one_hot,test_data,test_labels_one_hot,save_dir,model_name,num_classes,batch_size,epochs,img_row,img_col):\n",
        "    \n",
        "    spe = int( np.ceil(train_data.shape[0] / batch_size) )\n",
        "    \n",
        "    print('train samples',train_data.shape)\n",
        "    print('test samples',test_data.shape)\n",
        "    print('train labels',train_labels_one_hot.shape)\n",
        "    print('test labels',test_labels_one_hot.shape)\n",
        "    \n",
        "    train_labels_one_hot = np_utils.to_categorical(train_labels_one_hot)\n",
        "    test_labels_one_hot = np_utils.to_categorical(test_labels_one_hot)\n",
        "    \n",
        "\n",
        "     \n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3,3), padding='same',input_shape=(img_row,img_col,3)))\n",
        "    print('applying first CNN layer')\n",
        "     \n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D(32, (3, 3)))\n",
        "    \n",
        "    print('aplying second CNN layer')\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    print('applying third CNN layer')\n",
        "    model.add(Dropout(0.25))\n",
        "    \n",
        "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "    print('applying fourth CNN layer')\n",
        "    model.add(Activation('relu'))\n",
        "    \n",
        "    #model.add(Conv2D(64, (3, 3)))\n",
        "    \n",
        "    #print('applying fivth CNN layer')\n",
        "    #model.add(Activation('relu'))\n",
        "    #model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    #model.add(Dropout(0.25))\n",
        "    \n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128))\n",
        "    #print('applying sixth CNN layer')\n",
        "    model.add(Activation('relu'))\n",
        "    \n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(num_classes))\n",
        "    print('applying seventh CNN layer')\n",
        "    model.add(Activation('softmax'))\n",
        "    \n",
        "    # initiate RMSprop optimizer\n",
        "    opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
        "    \n",
        "    # Let's train the model using RMSprop\n",
        "    model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])\n",
        "    \n",
        "    #train_data = train_data.astype('float32')\n",
        "    #test_data = test_data.astype('float32')\n",
        "    #train_data /= 255\n",
        "    #test_data /= 255\n",
        "    \n",
        "    if not data_augmentation:\n",
        "        print('Not using data augmentation.')\n",
        "        print('fitting CNN model without data augmentation')\n",
        "        model.fit(train_data, train_labels_one_hot,\n",
        "                  batch_size=batch_size,\n",
        "                  epochs=epochs,\n",
        "                  validation_data=(test_data, test_labels_one_hot),\n",
        "                  shuffle=True)\n",
        "    else:\n",
        "        print('Using real-time data augmentation.')\n",
        "        print('fitting CNN model with data augmentation')\n",
        "        # This will do preprocessing and realtime data augmentation:\n",
        "        datagen = ImageDataGenerator(\n",
        "            featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "            samplewise_center=False,  # set each sample mean to 0\n",
        "            featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "            samplewise_std_normalization=False,  # divide each input by its std\n",
        "            zca_whitening=False,  # apply ZCA whitening\n",
        "            zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "            rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "            # randomly shift images horizontally (fraction of total width)\n",
        "            width_shift_range=0.1,\n",
        "            #steps_per_epoch = 1,\n",
        "            # randomly shift images vertically (fraction of total height)\n",
        "            height_shift_range=0.1,\n",
        "            shear_range=0.,  # set range for random shear\n",
        "            zoom_range=0.,  # set range for random zoom\n",
        "            channel_shift_range=0.,  # set range for random channel shifts\n",
        "            # set mode for filling points outside the input boundaries\n",
        "            fill_mode='nearest',\n",
        "            cval=0.,  # value used for fill_mode = \"constant\"\n",
        "            horizontal_flip=True,  # randomly flip images\n",
        "            vertical_flip=False,  # randomly flip images\n",
        "            # set rescaling factor (applied before any other transformation)\n",
        "            rescale=None,\n",
        "            # set function that will be applied on each input\n",
        "            preprocessing_function=None,\n",
        "            # image data format, either \"channels_first\" or \"channels_last\"\n",
        "            data_format=None,\n",
        "            # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "            validation_split=0.0)\n",
        "    \n",
        "        # Compute quantities required for feature-wise normalization\n",
        "        # (std, mean, and principal components if ZCA whitening is applied).\n",
        "        datagen.fit(train_data)\n",
        "    \n",
        "        # Fit the model on the batches generated by datagen.flow(). \n",
        "        #steps_per_epoch should be equivalent to the total number of samples divided by the batch size.\n",
        "        model.fit_generator(datagen.flow(train_data, train_labels_one_hot,\n",
        "                                         batch_size=batch_size),\n",
        "                            epochs=epochs,steps_per_epoch=spe,\n",
        "                            validation_data=(test_data, test_labels_one_hot))\n",
        "    \n",
        "    # Save model and weights\n",
        "    if not os.path.isdir(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "    model_path = os.path.join(save_dir, model_name)\n",
        "    model.save(model_path)\n",
        "    print('Saved trained model at %s ' % model_path)\n",
        "    \n",
        "    # Score trained model.\n",
        "    scores = model.evaluate(test_data, test_labels_one_hot, verbose=1)\n",
        "    print('Test loss:', scores[0])\n",
        "    print('Test accuracy:', scores[1])\n",
        "    \n",
        "    #model.save(\"CBA-model.h5\")\n",
        "    print('Trained on following stastics:')\n",
        "    print('train samples',train_data.shape)\n",
        "    print('test samples',test_data.shape)\n",
        "    print('train labels',train_labels_one_hot.shape)\n",
        "    print('test labels',test_labels_one_hot.shape)\n",
        "\n",
        "    return scores[0],scores[1] \n",
        "\n",
        "                                #FUNCTION MODULES end#\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "szNGmlrLzV7f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Running test/train data labels and CNN"
      ]
    },
    {
      "metadata": {
        "id": "1GkRPmO5zbkM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# testing\n",
        "train_data,train_labels_one_hot = TrainDataPrep(\"yogaposes/train\",128,128) \n",
        "# testing\n",
        "test_data,test_labels_one_hot = TestDataPrep(\"yogaposes/test\",128,128) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AsyT0IF0zgD2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_augmentation = True\n",
        "\n",
        "YogaCNNModel(train_data,train_labels_one_hot,test_data,test_labels_one_hot,\"finalmodel\",\"finalmodel.h5\",3,1,100,128,128)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t-Lo_rRUzvB9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Predict using saved model"
      ]
    },
    {
      "metadata": {
        "id": "LD0c6PcQzzsh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def PredictClass(modelPath,validationImagesPath):\n",
        "\n",
        "   \n",
        "    # dimensions of our images\n",
        "    img_width, img_height = 128, 128\n",
        "    \n",
        "    # load the model we saved\n",
        "    model = load_model('finalmodel.h5')\n",
        "    model.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\n",
        "    \n",
        "    # predicting images\n",
        "    img = image.load_img('frame14.jpg', target_size=(img_width, img_height))\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    \n",
        "    images = np.vstack([x])\n",
        "    classes = model.predict_classes(images, batch_size=10)\n",
        "    print(classes)\n",
        "    \n",
        "    #predictions = classifier.predict(images)\n",
        "\n",
        "    #print(predictions)\n",
        "    \n",
        "    # predicting multiple images at once\n",
        "#    img = image.load_img('test2.jpg', target_size=(img_width, img_height))\n",
        "#    y = image.img_to_array(img)\n",
        "#    y = np.expand_dims(y, axis=0)\n",
        "#    \n",
        "#    # pass the list of multiple images np.vstack()\n",
        "#    images = np.vstack([x, y])\n",
        "#    classes = model.predict_classes(images, batch_size=10)\n",
        "#    \n",
        "#    # print the classes, the images belong to\n",
        "#    print(classes)\n",
        "#    print(classes[0])\n",
        "#    print(classes[0][0])\n",
        "    \n",
        "    return classes"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}