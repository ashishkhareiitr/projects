{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pose_stick.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashishkhareiitr/projects/blob/master/pose_stick.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "hoLy5rdNCCva",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "1ca1231e-9205-4216-ad95-340c08f2bd5f"
      },
      "cell_type": "code",
      "source": [
        "!pip install pafy\n",
        "!pip install youtube_dl\n",
        "\n",
        "import sys\n",
        "import PIL.Image\n",
        "import cv2\n",
        "import os\n",
        "from sys import platform\n",
        "import re\n",
        "from os import listdir\n",
        "import ntpath #for retrieving filename\n",
        "import pafy\n",
        "import youtube_dl\n",
        "import pandas as pd"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pafy in /usr/local/lib/python3.6/dist-packages (0.5.4)\n",
            "Requirement already satisfied: youtube_dl in /usr/local/lib/python3.6/dist-packages (2018.10.29)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3fryPHCyKkSZ",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "cc656354-cb7c-4c21-c3e0-e780b422f701"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2e99faa7-7b3b-40ce-841e-e5af7efc4990\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-2e99faa7-7b3b-40ce-841e-e5af7efc4990\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving stickpose.zip to stickpose (1).zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Z0lnV65yKrOG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import io\n",
        "data = zipfile.ZipFile(io.BytesIO(uploaded['stickpose.zip']), 'r')\n",
        "data.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tXS0Sl1_K2th",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5564
        },
        "outputId": "69bd1744-c2f8-4bc5-b307-74ab50bc87ec"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "_nsre = re.compile('([0-9]+)')\n",
        "def natural_sort_key(s):\n",
        "    return [int(text) if text.isdigit() else text.lower()\n",
        "            for text in re.split(_nsre, s)]     \n",
        "\n",
        "\n",
        "def loadImages(path):\n",
        "    # return array of images\n",
        "    \n",
        "    imagesList = listdir(path)\n",
        "    imagesList.sort(key=natural_sort_key)\n",
        "    #imagesList = imagesList.sort()     \n",
        "    loadedImages = []\n",
        "    for image in imagesList:\n",
        "      if image is not None:\n",
        "        img = PIL.Image.open(path + image)\n",
        "        loadedImages.append(img)\n",
        "      else:\n",
        "        print('not loaded')\n",
        "    \n",
        "    \n",
        "    \n",
        "    return loadedImages\n",
        "\n",
        "\n",
        "# Specify the paths for the 2 files\n",
        "#protoFile = \"A://ISB//Capstone//PoseRetreival//OpenCVPoseEsti//pose_deploy_linevec.prototxt\"\n",
        "protoFile = \"pose_deploy_linevec_faster_4_stages.prototxt\"\n",
        "weightsFile = \"pose_iter_440000.caffemodel\"\n",
        " \n",
        "path_loadImages =  \"stickpose/\"\n",
        "imgs = loadImages(path_loadImages)\n",
        "\n",
        "\n",
        "#path_poseImages = r\"A://ISB//Capstone//PoseRetreival//OpenCVPoseEsti//poseImages//\"\n",
        "\n",
        "# Read the network into Memory\n",
        "net = cv2.dnn.readNetFromCaffe(protoFile, weightsFile)\n",
        "\n",
        "## GET FRAMES\n",
        "#pathOut = r\"A:/ISB/Capstone/PoseRetreival/FramePerSecond/\"\n",
        "#url = 'https://www.youtube.com/watch?v=AbPufvvYiSw'\n",
        "#url='https://www.youtube.com/watch?v=SCr5mEl9qbQ'\n",
        "#vPafy = pafy.new(url)\n",
        "#play = vPafy.getbest(preftype=\"webm\")\n",
        "\n",
        "#Get from the video from local folder\n",
        "vidcap = cv2.VideoCapture(\"yoga3.mp4\")\n",
        "\n",
        "\n",
        "#Get from the video from youtube\n",
        "#vidcap = cv2.VideoCapture(play.url)\n",
        "\n",
        "\n",
        "count = 0\n",
        "success = True\n",
        "'''\n",
        "while success:\n",
        "    success,image = vidcap.read()\n",
        "    print('read a new frame:',success)\n",
        "    if count%90 == 0 :\n",
        "     #    cv2.imshow('test',image)\n",
        "     #    cv2.imwrite(pathOut + 'frame%d.jpg'%count,image)\n",
        "     #    #cv2.waitKey(1000)\n",
        "     #    #cv2.destroyAllWindows()\n",
        "    #count+=1\n",
        "'''    \n",
        "\n",
        "\n",
        "    \n",
        "        \n",
        "for i in range(1,len(imgs)): \n",
        "        frame=cv2.imread(imgs[i-1].filename)\n",
        "        \n",
        "        # Read image\n",
        "        #frame = cv2.imread(\"A://ISB//Capstone//PoseRetreival//OpenCVPoseEsti//Image//Image3.jpg\")\n",
        "        \n",
        "        #frame = image\n",
        "        ###########Resize the image##################\n",
        "         \n",
        "        '''\n",
        "        #basewidth = 1280\n",
        "        #img = PIL.Image.open(\"A://ISB//Capstone//PoseRetreival//OpenCVPoseEsti//Image//Image3.jpg\")\n",
        "        width, height = img.size\n",
        "        #print(width,height)\n",
        "         \n",
        "        wpercent = (basewidth/float(img.size[0]))\n",
        "        hsize = int((float(img.size[1])*float(wpercent)))\n",
        "        img = img.resize((basewidth,hsize), PIL.Image.ANTIALIAS)\n",
        "        '''\n",
        "        #width, height = frame.size\n",
        "        height, width, channels = frame.shape\n",
        "        print(width,height)\n",
        "        #img.save('sompic.jpg') \n",
        "        if width <600:\n",
        "            x=width\n",
        "            y= 600 -x\n",
        "            width = width +x\n",
        "            height =  height +int((height/x)*y)\n",
        "            frame = cv2.resize(frame, (width, height)) \n",
        "       \n",
        "        ################################################\n",
        "        # Read image\n",
        "        #frame = cv2.imread(imgs[i-1].filename) #cv2.imread(\"sompic.jpg\")\n",
        "         \n",
        "        # Specify the input image dimensions\n",
        "        inWidth = width +0\n",
        "        inHeight = height + int((height/width)*0)\n",
        "        #print(inWidth,inHeight)\n",
        "        # Prepare the frame to be fed to the network\n",
        "        inpBlob = cv2.dnn.blobFromImage(frame, 1.0 / 255, (inWidth, inHeight), (0, 0, 0), swapRB=False, crop=False)\n",
        "         \n",
        "        # Set the prepared object as the input blob of the network\n",
        "        net.setInput(inpBlob)\n",
        "        \n",
        "        p=((0,1),(2,5),(3,6),(4,7),(8,11),(9,12),(10,13),(1,8),(1,11))        \n",
        "        output = net.forward()\n",
        "        \n",
        "        H = output.shape[2]\n",
        "        W = output.shape[3]\n",
        "        # Empty list to store the detected keypoints\n",
        "        points = {}\n",
        "        for i in range(0,13):\n",
        "            # confidence map of corresponding body's part.\n",
        "            probMap = output[0, i, :, :]\n",
        "        \n",
        "            # Find global maxima of the probMap.\n",
        "            minVal, prob, minLoc, point = cv2.minMaxLoc(probMap)\n",
        "             \n",
        "            # Scale the point to fit on the original image\n",
        "            #x = (frameWidth * point[0]) / W\n",
        "            #y = (frameHeight * point[1]) / H\n",
        "            x = (inWidth * point[0]) / W\n",
        "            y = (inHeight * point[1]) / H\n",
        "            if prob > 0.01 : \n",
        "                cv2.circle(frame, (int(x), int(y)), 15, (0, 255, 255), thickness=-1, lineType=cv2.FILLED)\n",
        "                cv2.putText(frame, \"{}\".format(i), (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 1.4, (0, 0, 255), 3, lineType=cv2.LINE_AA)\n",
        "         \n",
        "                # Add the point to the list if the probability is greater than the threshold\n",
        "                points.update({i:(int(x), int(y))})\n",
        "                #print(prob)\n",
        "            else :\n",
        "                #points.update(None)\n",
        "                 print(points)\n",
        "        \n",
        "        for pair in p:\n",
        "            partA = pair[0]\n",
        "            partB = pair[1]\n",
        "            print(partA,partB)\n",
        "            #if points[partA] and points[partB]:\n",
        "            if (partA in points) and (partB in points):\n",
        "                cv2.line(frame, points[partA], points[partB], (0, 255, 0), 3)    \n",
        "        \n",
        "        cv2.imwrite(os.path.join(os.getcwd(),\"stickpose{:d}.jpg\".format(count)),frame )         \n",
        "        #cv2.imshow(\"Output-Keypoints\",frame)\n",
        "        #cv2.waitKey(5000)\n",
        "        #cv2.destroyAllWindows()\n",
        "        count+=1"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "474 327\n",
            "0 1\n",
            "2 5\n",
            "3 6\n",
            "4 7\n",
            "8 11\n",
            "9 12\n",
            "10 13\n",
            "1 8\n",
            "1 11\n",
            "480 480\n",
            "0 1\n",
            "2 5\n",
            "3 6\n",
            "4 7\n",
            "8 11\n",
            "9 12\n",
            "10 13\n",
            "1 8\n",
            "1 11\n",
            "500 500\n",
            "0 1\n",
            "2 5\n",
            "3 6\n",
            "4 7\n",
            "8 11\n",
            "9 12\n",
            "10 13\n",
            "1 8\n",
            "1 11\n",
            "1000 667\n",
            "0 1\n",
            "2 5\n",
            "3 6\n",
            "4 7\n",
            "8 11\n",
            "9 12\n",
            "10 13\n",
            "1 8\n",
            "1 11\n",
            "1080 1108\n",
            "0 1\n",
            "2 5\n",
            "3 6\n",
            "4 7\n",
            "8 11\n",
            "9 12\n",
            "10 13\n",
            "1 8\n",
            "1 11\n",
            "480 480\n",
            "0 1\n",
            "2 5\n",
            "3 6\n",
            "4 7\n",
            "8 11\n",
            "9 12\n",
            "10 13\n",
            "1 8\n",
            "1 11\n",
            "960 720\n",
            "0 1\n",
            "2 5\n",
            "3 6\n",
            "4 7\n",
            "8 11\n",
            "9 12\n",
            "10 13\n",
            "1 8\n",
            "1 11\n",
            "500 333\n",
            "0 1\n",
            "2 5\n",
            "3 6\n",
            "4 7\n",
            "8 11\n",
            "9 12\n",
            "10 13\n",
            "1 8\n",
            "1 11\n",
            "640 640\n",
            "0 1\n",
            "2 5\n",
            "3 6\n",
            "4 7\n",
            "8 11\n",
            "9 12\n",
            "10 13\n",
            "1 8\n",
            "1 11\n",
            "720 810\n",
            "0 1\n",
            "2 5\n",
            "3 6\n",
            "4 7\n",
            "8 11\n",
            "9 12\n",
            "10 13\n",
            "1 8\n",
            "1 11\n",
            "570 310\n",
            "{0: (310, 55), 1: (350, 111), 2: (406, 103), 3: (223, 190), 4: (167, 270), 5: (310, 119), 6: (223, 214), 7: (167, 270), 8: (374, 238), 9: (231, 87)}\n",
            "0 1\n",
            "2 5\n",
            "3 6\n",
            "4 7\n",
            "8 11\n",
            "9 12\n",
            "10 13\n",
            "1 8\n",
            "1 11\n",
            "500 500\n",
            "0 1\n",
            "2 5\n",
            "3 6\n",
            "4 7\n",
            "8 11\n",
            "9 12\n",
            "10 13\n",
            "1 8\n",
            "1 11\n",
            "400 300\n",
            "0 1\n",
            "2 5\n",
            "3 6\n",
            "4 7\n",
            "8 11\n",
            "9 12\n",
            "10 13\n",
            "1 8\n",
            "1 11\n",
            "768 1024\n",
            "0 1\n",
            "2 5\n",
            "3 6\n",
            "4 7\n",
            "8 11\n",
            "9 12\n",
            "10 13\n",
            "1 8\n",
            "1 11\n",
            "400 500\n",
            "0 1\n",
            "2 5\n",
            "3 6\n",
            "4 7\n",
            "8 11\n",
            "9 12\n",
            "10 13\n",
            "1 8\n",
            "1 11\n",
            "450 360\n",
            "0 1\n",
            "2 5\n",
            "3 6\n",
            "4 7\n",
            "8 11\n",
            "9 12\n",
            "10 13\n",
            "1 8\n",
            "1 11\n",
            "640 360\n",
            "0 1\n",
            "2 5\n",
            "3 6\n",
            "4 7\n",
            "8 11\n",
            "9 12\n",
            "10 13\n",
            "1 8\n",
            "1 11\n",
            "1280 720\n",
            "0 1\n",
            "2 5\n",
            "3 6\n",
            "4 7\n",
            "8 11\n",
            "9 12\n",
            "10 13\n",
            "1 8\n",
            "1 11\n",
            "1280 720\n",
            "0 1\n",
            "2 5\n",
            "3 6\n",
            "4 7\n",
            "8 11\n",
            "9 12\n",
            "10 13\n",
            "1 8\n",
            "1 11\n",
            "1280 720\n",
            "0 1\n",
            "2 5\n",
            "3 6\n",
            "4 7\n",
            "8 11\n",
            "9 12\n",
            "10 13\n",
            "1 8\n",
            "1 11\n",
            "640 360\n",
            "{0: (344, 96), 1: (344, 184), 2: (272, 184), 3: (240, 336), 4: (320, 272), 5: (424, 192), 6: (448, 336), 7: (368, 280), 8: (320, 352)}\n",
            "{0: (344, 96), 1: (344, 184), 2: (272, 184), 3: (240, 336), 4: (320, 272), 5: (424, 192), 6: (448, 336), 7: (368, 280), 8: (320, 352)}\n",
            "{0: (344, 96), 1: (344, 184), 2: (272, 184), 3: (240, 336), 4: (320, 272), 5: (424, 192), 6: (448, 336), 7: (368, 280), 8: (320, 352)}\n",
            "{0: (344, 96), 1: (344, 184), 2: (272, 184), 3: (240, 336), 4: (320, 272), 5: (424, 192), 6: (448, 336), 7: (368, 280), 8: (320, 352)}\n",
            "0 1\n",
            "2 5\n",
            "3 6\n",
            "4 7\n",
            "8 11\n",
            "9 12\n",
            "10 13\n",
            "1 8\n",
            "1 11\n",
            "860 645\n",
            "0 1\n",
            "2 5\n",
            "3 6\n",
            "4 7\n",
            "8 11\n",
            "9 12\n",
            "10 13\n",
            "1 8\n",
            "1 11\n",
            "500 400\n",
            "{0: (368, 136), 1: (368, 176), 2: (336, 168), 3: (344, 272), 4: (384, 304), 5: (400, 192), 6: (344, 264), 7: (384, 312), 8: (392, 296), 9: (344, 360)}\n",
            "0 1\n",
            "2 5\n",
            "3 6\n",
            "4 7\n",
            "8 11\n",
            "9 12\n",
            "10 13\n",
            "1 8\n",
            "1 11\n",
            "159 240\n",
            "0 1\n",
            "2 5\n",
            "3 6\n",
            "4 7\n",
            "8 11\n",
            "9 12\n",
            "10 13\n",
            "1 8\n",
            "1 11\n",
            "600 450\n",
            "{0: (312, 228), 1: (320, 78), 2: (328, 78), 3: (296, 142), 4: (328, 173), 5: (312, 86), 6: (304, 142), 7: (328, 173), 8: (320, 181), 9: (344, 205)}\n",
            "0 1\n",
            "2 5\n",
            "3 6\n",
            "4 7\n",
            "8 11\n",
            "9 12\n",
            "10 13\n",
            "1 8\n",
            "1 11\n",
            "1300 1173\n",
            "{0: (765, 303), 1: (765, 319), 2: (693, 295), 3: (574, 438), 4: (693, 383), 5: (893, 582), 6: (582, 438), 7: (622, 414), 8: (845, 670), 9: (829, 686)}\n",
            "0 1\n",
            "2 5\n",
            "3 6\n",
            "4 7\n",
            "8 11\n",
            "9 12\n",
            "10 13\n",
            "1 8\n",
            "1 11\n",
            "1280 720\n",
            "0 1\n",
            "2 5\n",
            "3 6\n",
            "4 7\n",
            "8 11\n",
            "9 12\n",
            "10 13\n",
            "1 8\n",
            "1 11\n",
            "496 368\n",
            "0 1\n",
            "2 5\n",
            "3 6\n",
            "4 7\n",
            "8 11\n",
            "9 12\n",
            "10 13\n",
            "1 8\n",
            "1 11\n",
            "1280 720\n",
            "0 1\n",
            "2 5\n",
            "3 6\n",
            "4 7\n",
            "8 11\n",
            "9 12\n",
            "10 13\n",
            "1 8\n",
            "1 11\n",
            "1280 720\n",
            "0 1\n",
            "2 5\n",
            "3 6\n",
            "4 7\n",
            "8 11\n",
            "9 12\n",
            "10 13\n",
            "1 8\n",
            "1 11\n",
            "1280 720\n",
            "0 1\n",
            "2 5\n",
            "3 6\n",
            "4 7\n",
            "8 11\n",
            "9 12\n",
            "10 13\n",
            "1 8\n",
            "1 11\n",
            "640 640\n",
            "{0: (312, 136), 1: (296, 176), 2: (288, 168), 3: (280, 328), 4: (320, 288), 5: (280, 304), 6: (320, 416), 7: (320, 288), 8: (328, 304), 9: (320, 368)}\n",
            "0 1\n",
            "2 5\n",
            "3 6\n",
            "4 7\n",
            "8 11\n",
            "9 12\n",
            "10 13\n",
            "1 8\n",
            "1 11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "t8JDgds99OrI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "77645dde-931b-45bf-a8f8-0b15af4870e9"
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Object detection\n",
        "================\n",
        " \n",
        "Shape dataset\n",
        "\"\"\"\n",
        " \n",
        "import os\n",
        " \n",
        "import keras_rcnn\n",
        "import keras_rcnn.datasets.shape\n",
        "import keras_rcnn.preprocessing\n",
        "import keras_rcnn.utils\n",
        "import keras_rcnn.models\n",
        "import numpy\n",
        "import keras\n",
        " \n",
        "import matplotlib\n",
        "import matplotlib.backends.backend_pdf\n",
        " \n",
        "import pickle\n",
        " \n",
        "print(os.getcwd())\n",
        " \n",
        " \n",
        "def main():\n",
        "    training_dictionary, test_dictionary = keras_rcnn.datasets.shape.load_data()\n",
        " \n",
        "    categories = {\"circle\": 1, \"rectangle\": 2, \"triangle\": 3}\n",
        " \n",
        "    generator = keras_rcnn.preprocessing.ObjectDetectionGenerator()\n",
        " \n",
        "    generator = generator.flow_from_dictionary(\n",
        "        dictionary=training_dictionary,\n",
        "        categories=categories,\n",
        "        target_size=(224, 224)\n",
        "    )\n",
        " \n",
        "    validation_data = keras_rcnn.preprocessing.ObjectDetectionGenerator()\n",
        " \n",
        "    validation_data = validation_data.flow_from_dictionary(\n",
        "        dictionary=test_dictionary,\n",
        "        categories=categories,\n",
        "        target_size=(224, 224),\n",
        "        shuffle=False\n",
        "    )\n",
        " \n",
        "    target, _ = generator.next()\n",
        " \n",
        "    # Plotting expected predictions\n",
        "    target_bounding_boxes, target_categories, target_images, target_masks, target_metadata = target\n",
        "    target_images = numpy.squeeze(target_images)\n",
        "    target_bounding_boxes = numpy.squeeze(target_bounding_boxes)\n",
        "    target_categories = numpy.argmax(target_categories, -1)\n",
        "    target_categories = numpy.squeeze(target_categories)\n",
        "    keras_rcnn.utils.show_bounding_boxes(target_images, target_bounding_boxes, target_categories)\n",
        "    matplotlib.pyplot.show()\n",
        "    matplotlib.pyplot.gcf().clear()\n",
        " \n",
        "    model = keras_rcnn.models.RCNN((224, 224, 3), [\"circle\", \"rectangle\", \"triangle\"])\n",
        " \n",
        "    optimizer = keras.optimizers.Adam()\n",
        "    model.compile(optimizer)\n",
        " \n",
        "    model.fit_generator(\n",
        "        epochs=100,\n",
        "        generator=generator,\n",
        "        validation_data=validation_data\n",
        "    )\n",
        " \n",
        "    # TODO: save model\n",
        "    # model.save('rcnn_quickstart_1_epoch_model.h5')\n",
        " \n",
        "    predictions = model.predict_generator(validation_data)\n",
        " \n",
        "    pickle.dump(predictions, open('rcnn_quickstart_100_epochs_model_predictions.p', 'wb'))\n",
        "    predictions = pickle.load(open('rcnn_quickstart_100_epochs_model_predictions.p', 'rb'))\n",
        " \n",
        "    # Example prediction on validation data\n",
        "    (target_bounding_boxes, target_categories, target_images, target_masks, _), _ = validation_data[60]\n",
        "    target_images = numpy.squeeze(target_images)\n",
        "    predicted_bad = predictions[0][60]\n",
        "    predicted_bad = numpy.squeeze(predicted_bad)\n",
        "    predicted_bad_category = predictions[1][60]\n",
        "    predicted_bad_category = numpy.squeeze(predicted_bad_category)\n",
        "    predicted_bad_category_idx = numpy.argmax(predicted_bad_category, axis=1)\n",
        "    keras_rcnn.utils.show_bounding_boxes(target_images, predicted_bad, predicted_bad_category_idx)\n",
        "    matplotlib.pyplot.show()\n",
        "    matplotlib.pyplot.gcf().clear()\n",
        " \n",
        "    # Plotting perfect predictions first\n",
        "    pdf = matplotlib.backends.backend_pdf.PdfPages(\"rcnn_quickstart_100_epochs_model_expected_plot.pdf\")\n",
        "    for i in range(len(validation_data)):\n",
        "        (target_bounding_boxes, target_categories, target_images, target_masks, _), _ = validation_data[i]\n",
        "        target_bounding_boxes = numpy.squeeze(target_bounding_boxes)\n",
        "        target_images = numpy.squeeze(target_images)\n",
        "        target_categories = numpy.argmax(target_categories, -1)\n",
        "        target_categories = numpy.squeeze(target_categories)\n",
        "        keras_rcnn.utils.show_bounding_boxes(target_images, target_bounding_boxes, target_categories)\n",
        "        pdf.savefig()\n",
        "        matplotlib.pyplot.gcf().clear()\n",
        "    pdf.close()\n",
        " \n",
        "    pdf = matplotlib.backends.backend_pdf.PdfPages(\"rcnn_quickstart_100_epochs_model_predictions_plot.pdf\")\n",
        "    for i in range(len(validation_data)):\n",
        "        (target_bounding_boxes, target_categories, target_images, target_masks, _), _ = validation_data[i]\n",
        "        target_images = numpy.squeeze(target_images)\n",
        "        predicted_bad = predictions[0][i]\n",
        "        predicted_bad = numpy.squeeze(predicted_bad)\n",
        "        predicted_bad_category = predictions[1][i]\n",
        "        predicted_bad_category = numpy.squeeze(predicted_bad_category)\n",
        "        predicted_bad_category_idx = numpy.argmax(predicted_bad_category, axis=1)\n",
        "        keras_rcnn.utils.show_bounding_boxes(target_images, predicted_bad, predicted_bad_category_idx)\n",
        "        pdf.savefig()\n",
        "        matplotlib.pyplot.gcf().clear()\n",
        "    pdf.close()\n",
        " \n",
        " \n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-e8fc76cb1f0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkeras_rcnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras_rcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras_rcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras_rcnn'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "60D8wAtW97bW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        " \n",
        "\n",
        "import keras\n",
        " \n",
        "import matplotlib\n",
        "import matplotlib.backends.backend_pdf\n",
        " \n",
        "import pickle\n",
        "\n",
        "import keras_rcnn\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MMFruoV5-OBp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "6dfdc6aa-eed4-4248-b3fd-d57fe3dd2202"
      },
      "cell_type": "code",
      "source": [
        "!pip install keras_rcnn.datasets.shape\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras_rcnn.datasets.shape\n",
            "\u001b[31m  Could not find a version that satisfies the requirement keras_rcnn.datasets.shape (from versions: )\u001b[0m\n",
            "\u001b[31mNo matching distribution found for keras_rcnn.datasets.shape\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QE0GRKkWy-hr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}