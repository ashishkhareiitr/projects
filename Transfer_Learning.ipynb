{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer_Learning.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashishkhareiitr/projects/blob/master/Transfer_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "PK9EqsY21sJ7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import glob\n",
        "import argparse\n",
        "import matplotlib\n",
        "matplotlib.use('agg')\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras import backend as K\n",
        "from keras import __version__\n",
        "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, AveragePooling2D, GlobalAveragePooling2D, Input, Flatten, Dropout\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "\n",
        "IM_WIDTH, IM_HEIGHT = 299, 299 #fixed size for InceptionV3\n",
        "NB_EPOCHS = 3\n",
        "BAT_SIZE = 32\n",
        "FC_SIZE = 1024\n",
        "#NB_IV3_LAYERS_TO_FREEZE = 172\n",
        "\n",
        "\n",
        "def get_nb_files(directory):\n",
        "    \"\"\"Get number of files by searching directory recursively\"\"\"\n",
        "    if not os.path.exists(directory):\n",
        "        return 0\n",
        "    cnt = 0\n",
        "    for r, dirs, files in os.walk(directory):\n",
        "        for dr in dirs:\n",
        "            cnt += len(glob.glob(os.path.join(r, dr + \"/*\")))\n",
        "    return cnt\n",
        "\n",
        "\n",
        "def setup_to_transfer_learn(model, base_model):\n",
        "    \"\"\"Freeze all layers and compile the model\"\"\"\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "    model.compile(optimizer='rmsprop',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "\n",
        "def add_new_last_layer(base_model, nb_classes):\n",
        "    \"\"\"Add last layer to the convnet\n",
        "    \n",
        "    Args:\n",
        "        base_model: keras model excluding top\n",
        "        nb_classes: # of classes\n",
        "        \n",
        "    Returns:\n",
        "        new keras model with last layer\n",
        "    \"\"\"\n",
        "    x = base_model.output\n",
        "    x = AveragePooling2D((8, 8), border_mode='valid', name='avg_pool')(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    x = Flatten()(x)\n",
        "    predictions = Dense(2, activation='softmax')(x)\n",
        "    model = Model(input=base_model.input, output=predictions)\n",
        "    return model\n",
        "    \n",
        "\"\"\"\n",
        "def setup_to_finetune(model):\n",
        "  Freeze the bottom NB_IV3_LAYERS and retrain the remaining top layers.\n",
        "  note: NB_IV3_LAYERS corresponds to the top 2 inception blocks in the inceptionv3 arch\n",
        "  Args:\n",
        "    model: keras model\n",
        "  \n",
        "  for layer in model.layers[:NB_IV3_LAYERS_TO_FREEZE]:\n",
        "     layer.trainable = False\n",
        "  for layer in model.layers[NB_IV3_LAYERS_TO_FREEZE:]:\n",
        "     layer.trainable = True\n",
        "  model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\"\"\"\n",
        "\n",
        "def train(args):\n",
        "    \"\"\"Use transfer learning and fine-tuning to train a network on a new dataset\"\"\"\n",
        "    train_img = 'two_class_data/train1/'\n",
        "    validation_img = 'two_class_data/test1/'\n",
        "    \n",
        "    nb_epoch = int(args.nb_epoch)\n",
        "    nb_train_samples = get_nb_files(train_img)\n",
        "    nb_classes = len(glob.glob(train_img + \"/*\"))\n",
        "    # data prep\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rotation_range=40,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest')\n",
        "\n",
        "    validation_datagen = ImageDataGenerator(\n",
        "        rotation_range=40,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest')\n",
        "\n",
        "    \n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "\t\t\ttrain_img,\n",
        "\t\t\ttarget_size=(299, 299),\n",
        "\t\t\tbatch_size=32,\n",
        "\t\t\tclass_mode='categorical'\n",
        "\t\t\t)\n",
        "    validation_generator = validation_datagen.flow_from_directory(\n",
        "\t\t\tvalidation_img,\n",
        "\t\t\ttarget_size=(299, 299),\n",
        "\t\t\tbatch_size=32,\n",
        "\t\t\tclass_mode='categorical'\n",
        "\t\t\t)\n",
        "    if(K.image_dim_ordering() == 'th'):\n",
        "        input_tensor = Input(shape=(3, 299, 299))\n",
        "    else:\n",
        "        input_tensor = Input(shape=(299, 299, 3))\n",
        "    \n",
        "    # setup model\n",
        "    base_model = InceptionV3(input_tensor = input_tensor,weights='imagenet', include_top=False) #include_top=False excludes final FC layer\n",
        "    model = add_new_last_layer(base_model, nb_classes)\n",
        "    \n",
        "    # transfer learning\n",
        "    setup_to_transfer_learn(model, base_model)\n",
        "    \n",
        "    \n",
        "    \n",
        "    history_tl = model.fit_generator(train_generator,\n",
        "                                   samples_per_epoch=320,\n",
        "                                   nb_epoch=nb_epoch,\n",
        "                                   validation_data=validation_generator,\n",
        "                                   nb_val_samples=64) \n",
        "    model.save(args.output_model_file)\n",
        "    if args.plot:\n",
        "        plot_training(history_tl)\n",
        "        \n",
        "        \n",
        "def plot_training(history):\n",
        "    acc = history.history['acc']\n",
        "    val_acc = history.history['val_acc']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    epochs = range(len(acc))\n",
        "    \n",
        "    plt.plot(epochs, acc, 'r.')\n",
        "    plt.plot(epochs, val_acc, 'r')\n",
        "    plt.title('Training and validation accuracy')\n",
        "    plt.savefig('accuracy.png')\n",
        "    \n",
        "    plt.figure()\n",
        "    plt.plot(epochs, loss, 'r.')\n",
        "    plt.plot(epochs, val_loss, 'r-')\n",
        "    plt.title('Training and validation loss')\n",
        "    plt.savefig('loss.png')\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    \n",
        "    \n",
        "    a = argparse.ArgumentParser()\n",
        "    a.add_argument(\"--nb_epoch\", default=NB_EPOCHS)\n",
        "    a.add_argument(\"--batch_size\", default=BAT_SIZE)\n",
        "    a.add_argument(\"--plot\", action=\"store_true\")\n",
        "    a.add_argument(\"--output_model_file\", default=\"inceptionv3-model.h5\")\n",
        "    args = a.parse_args()\n",
        "    \n",
        "train(args)  \n",
        "\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4ZBxprUe79IJ",
        "colab_type": "code",
        "outputId": "df609165-f496-4b3e-dda4-9aaca1f2dde7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "!ls \"/content/drive/My Drive/\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n",
            "'Blank Quiz (1).gform'\n",
            "'Blank Quiz.gform'\n",
            "'Colab Notebooks'\n",
            " data\n",
            " DCGroupSubmission.py\n",
            " GroupSubmission_ISBTwitterVaccineDV3v1.twbx\n",
            " inceptionv3-ft.model\n",
            "'MachineLearningProject (2).ipynb'\n",
            " MachineLearningProject.ipynb\n",
            "'NEW DATA.zip'\n",
            " sadanand\n",
            " sentiment.zip\n",
            " transfer.py\n",
            " two_class.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "e229xr6JNYcN",
        "colab_type": "code",
        "outputId": "8b6bf30e-7d0a-4d44-844d-57e0226e0ba4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5141
        }
      },
      "cell_type": "code",
      "source": [
        "!unzip \"/content/drive/My Drive/two_class.zip\" "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/My Drive/two_class.zip\n",
            "   creating: two_class_data/\n",
            "   creating: two_class_data/test1/\n",
            "   creating: two_class_data/test1/1/\n",
            "  inflating: two_class_data/test1/1/cropyolo0.jpg  \n",
            "  inflating: two_class_data/test1/1/cropyolo1.jpg  \n",
            "  inflating: two_class_data/test1/1/cropyolo10.jpg  \n",
            "  inflating: two_class_data/test1/1/cropyolo11.jpg  \n",
            "  inflating: two_class_data/test1/1/cropyolo12.jpg  \n",
            "  inflating: two_class_data/test1/1/cropyolo13.jpg  \n",
            "  inflating: two_class_data/test1/1/cropyolo14.jpg  \n",
            "  inflating: two_class_data/test1/1/cropyolo15.jpg  \n",
            "  inflating: two_class_data/test1/1/cropyolo16.jpg  \n",
            "  inflating: two_class_data/test1/1/cropyolo17.jpg  \n",
            "  inflating: two_class_data/test1/1/cropyolo18.jpg  \n",
            "  inflating: two_class_data/test1/1/cropyolo19.jpg  \n",
            "  inflating: two_class_data/test1/1/cropyolo2.jpg  \n",
            "  inflating: two_class_data/test1/1/cropyolo20.jpg  \n",
            "  inflating: two_class_data/test1/1/cropyolo21.jpg  \n",
            "  inflating: two_class_data/test1/1/cropyolo22.jpg  \n",
            "  inflating: two_class_data/test1/1/cropyolo23.jpg  \n",
            "  inflating: two_class_data/test1/1/cropyolo3.jpg  \n",
            "  inflating: two_class_data/test1/1/cropyolo4.jpg  \n",
            "  inflating: two_class_data/test1/1/cropyolo5.jpg  \n",
            "  inflating: two_class_data/test1/1/cropyolo6.jpg  \n",
            "  inflating: two_class_data/test1/1/cropyolo7.jpg  \n",
            "  inflating: two_class_data/test1/1/cropyolo8.jpg  \n",
            "  inflating: two_class_data/test1/1/cropyolo9.jpg  \n",
            "   creating: two_class_data/test1/2/\n",
            "  inflating: two_class_data/test1/2/cropyolo10.jpg  \n",
            "  inflating: two_class_data/test1/2/cropyolo11.jpg  \n",
            "  inflating: two_class_data/test1/2/cropyolo12.jpg  \n",
            "  inflating: two_class_data/test1/2/cropyolo13.jpg  \n",
            "  inflating: two_class_data/test1/2/cropyolo14.jpg  \n",
            "  inflating: two_class_data/test1/2/cropyolo2.jpg  \n",
            "  inflating: two_class_data/test1/2/cropyolo24.jpg  \n",
            "  inflating: two_class_data/test1/2/cropyolo3.jpg  \n",
            "  inflating: two_class_data/test1/2/cropyolo4.jpg  \n",
            "  inflating: two_class_data/test1/2/cropyolo43.jpg  \n",
            "  inflating: two_class_data/test1/2/cropyolo44.jpg  \n",
            "  inflating: two_class_data/test1/2/cropyolo45.jpg  \n",
            "  inflating: two_class_data/test1/2/cropyolo47.jpg  \n",
            "  inflating: two_class_data/test1/2/cropyolo48.jpg  \n",
            "  inflating: two_class_data/test1/2/cropyolo49.jpg  \n",
            "  inflating: two_class_data/test1/2/cropyolo5.jpg  \n",
            "  inflating: two_class_data/test1/2/cropyolo50.jpg  \n",
            "  inflating: two_class_data/test1/2/cropyolo51.jpg  \n",
            "  inflating: two_class_data/test1/2/cropyolo52.jpg  \n",
            "  inflating: two_class_data/test1/2/cropyolo53.jpg  \n",
            "  inflating: two_class_data/test1/2/cropyolo54.jpg  \n",
            "  inflating: two_class_data/test1/2/cropyolo55.jpg  \n",
            "  inflating: two_class_data/test1/2/cropyolo65.jpg  \n",
            "  inflating: two_class_data/test1/2/cropyolo67.jpg  \n",
            "  inflating: two_class_data/test1/2/cropyolo68.jpg  \n",
            "  inflating: two_class_data/test1/2/cropyolo73.jpg  \n",
            "  inflating: two_class_data/test1/2/cropyolo74.jpg  \n",
            "  inflating: two_class_data/test1/2/cropyolo9.jpg  \n",
            "   creating: two_class_data/train1/\n",
            "   creating: two_class_data/train1/1/\n",
            "  inflating: two_class_data/train1/1/cropyolo0.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo1.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo10.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo11.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo12 (1).jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo12.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo13 (1).jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo13.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo15 (1).jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo15.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo16 (1).jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo16.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo17 (1).jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo17.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo18 (1).jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo18.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo19.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo21.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo22.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo24.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo25.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo26.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo27.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo29.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo3 (1).jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo3.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo30.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo31.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo32.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo33.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo35.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo37.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo38.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo39.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo40.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo41.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo42.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo43.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo44.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo45.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo46.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo47.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo48.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo49.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo5 (1).jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo5.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo50.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo51.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo52.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo53.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo54.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo55.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo56.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo57.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo58.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo59.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo60.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo61.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo63.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo64.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo66.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo67.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo68.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo69.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo7.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo70.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo71.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo72.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo73.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo74.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo75.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo77.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo79.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo8.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo80.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo81.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo82.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo83.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo84.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo85.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo86.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo9.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo90.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo91.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo92.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo93.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo94.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo95.jpg  \n",
            "  inflating: two_class_data/train1/1/cropyolo96.jpg  \n",
            "   creating: two_class_data/train1/2/\n",
            "  inflating: two_class_data/train1/2/cropyolo1.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo100.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo101.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo102.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo103.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo104.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo105.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo106.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo107.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo108.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo109.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo11.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo115.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo116.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo117.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo118.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo119.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo12.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo120.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo121.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo122.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo123.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo124.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo125.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo128.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo129.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo13.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo130.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo131.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo132.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo134.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo137.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo138.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo139.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo14.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo140.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo141.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo142.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo143.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo144.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo145.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo146.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo147.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo148.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo149.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo15.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo150.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo151.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo152.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo153.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo154.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo156.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo16.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo17.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo175.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo176.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo177.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo178.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo179.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo18.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo180.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo181.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo182.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo183.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo19.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo20.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo21.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo22.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo23.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo24.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo25.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo27.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo28.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo29.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo30.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo31.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo32.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo35.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo37.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo38.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo39.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo4.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo40.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo41.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo42.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo43.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo44.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo45.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo46.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo47.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo49.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo5.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo50.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo51.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo53.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo54.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo55.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo56.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo6.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo61.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo62.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo63.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo64.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo66.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo68.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo69.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo70.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo71.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo72.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo73.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo75.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo76.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo78.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo8.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo80.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo81.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo82.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo85.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo86.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo88.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo89.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo9.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo90.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo91.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo93.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo95.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo96.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo97.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo98.jpg  \n",
            "  inflating: two_class_data/train1/2/cropyolo99.jpg  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0j6qRY3hPBNF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cp /content/drive/My\\ Drive/transfer.py ./"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jtDfG3UGRbuM",
        "colab_type": "code",
        "outputId": "c452f085-7074-4067-8a35-5a236bf3084b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        }
      },
      "cell_type": "code",
      "source": [
        "!python transfer.py"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "Found 994 images belonging to 8 classes.\n",
            "Found 163 images belonging to 8 classes.\n",
            "transfer.py:56: UserWarning: Update your `AveragePooling2D` call to the Keras 2 API: `AveragePooling2D((8, 8), name=\"avg_pool\", padding=\"valid\")`\n",
            "  x = AveragePooling2D((8, 8), border_mode='valid', name='avg_pool')(x)\n",
            "transfer.py:60: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
            "  model = Model(input=base_model.input, output=predictions)\n",
            "transfer.py:137: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "  nb_val_samples=64)\n",
            "transfer.py:137: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=<keras_pre..., steps_per_epoch=10, epochs=3, validation_steps=64)`\n",
            "  nb_val_samples=64)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 761s 76s/step - loss: 2.1183 - acc: 0.2219 - val_loss: 2.2060 - val_acc: 0.1991\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 737s 74s/step - loss: 1.9687 - acc: 0.2875 - val_loss: 2.2233 - val_acc: 0.2065\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 736s 74s/step - loss: 1.8593 - acc: 0.3281 - val_loss: 2.0885 - val_acc: 0.2585\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5irsjB7zvRoi",
        "colab_type": "code",
        "outputId": "157cb7d6-0249-4c09-ac04-8fbaf3931fcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 661
        }
      },
      "cell_type": "code",
      "source": [
        "!python transfer.py --nb_epoch 5 --batch_size 320 --plot --output_model_file inception-model.h5"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "Found 219 images belonging to 2 classes.\n",
            "Found 52 images belonging to 2 classes.\n",
            "2018-11-18 17:45:20.977911: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2018-11-18 17:45:20.978534: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 11.17GiB freeMemory: 11.10GiB\n",
            "2018-11-18 17:45:20.978582: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2018-11-18 17:45:21.892597: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2018-11-18 17:45:21.892673: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2018-11-18 17:45:21.892699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2018-11-18 17:45:21.892950: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2018-11-18 17:45:21.893043: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10758 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 1s 0us/step\n",
            "transfer.py:56: UserWarning: Update your `AveragePooling2D` call to the Keras 2 API: `AveragePooling2D((8, 8), name=\"avg_pool\", padding=\"valid\")`\n",
            "  x = AveragePooling2D((8, 8), border_mode='valid', name='avg_pool')(x)\n",
            "transfer.py:60: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
            "  model = Model(input=base_model.input, output=predictions)\n",
            "transfer.py:137: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "  nb_val_samples=64)\n",
            "transfer.py:137: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=<keras_pre..., steps_per_epoch=10, epochs=5, validation_steps=64)`\n",
            "  nb_val_samples=64)\n",
            "Epoch 1/5\n",
            "10/10 [==============================] - 57s 6s/step - loss: 0.8520 - acc: 0.4961 - val_loss: 0.9045 - val_acc: 0.5319\n",
            "Epoch 2/5\n",
            "10/10 [==============================] - 47s 5s/step - loss: 0.6889 - acc: 0.5962 - val_loss: 0.7117 - val_acc: 0.4820\n",
            "Epoch 3/5\n",
            "10/10 [==============================] - 47s 5s/step - loss: 0.6579 - acc: 0.6333 - val_loss: 0.7695 - val_acc: 0.6286\n",
            "Epoch 4/5\n",
            "10/10 [==============================] - 46s 5s/step - loss: 0.5872 - acc: 0.7021 - val_loss: 0.6725 - val_acc: 0.5397\n",
            "Epoch 5/5\n",
            "10/10 [==============================] - 45s 4s/step - loss: 0.6165 - acc: 0.6928 - val_loss: 0.8255 - val_acc: 0.5325\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LYpx-UB6idw6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cp inceptionv3-ft.model /content/drive/My\\ Drive/"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}